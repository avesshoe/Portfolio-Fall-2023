---
title: "11/06"
output: html_document
date: "2023-11-06"
---

```{r}
library(tidyverse)
library(janitor)
library(here)
library(openmeteo)
library(lubridate)
```

## Read data

```{r}
BikeData = read_csv(here("202309-capitalbikeshare-tripdata.csv"))
```

```{r}
df2s=BikeData %>% 
  select(rideable_type,member_casual,
                    contains("start"),ride_id) %>% 
  mutate(start_stop="start") %>%
  rename(t=started_at,
         station_name=start_station_name,
         station_id=start_station_id,
         lat=start_lat,
         lng=start_lng)
df2e=BikeData %>% 
  select(ride_id,rideable_type,member_casual,
                    contains("end")) %>%
  mutate(start_stop="stop") %>%
  rename(t=ended_at,
         station_name=end_station_name,
         station_id=end_station_id,
         lat=end_lat,
         lng=end_lng)
 
df2=bind_rows(df2s,df2e) %>%
  arrange(t) %>%
  mutate(rider_delta=(start_stop=="start")*2-1) %>% #change in ridership 
  mutate(riders=cumsum(rider_delta)) %>%
  relocate(riders,.after=t)

```

## EDA Plots

```{r}
df2 %>% 
  ggplot(aes(t,riders)) +
  geom_line()

```
## Subsample Dataset

p1 is original data
```{r}
p1=df2 %>% 
  filter(day(t)==18) %>%
  ggplot(aes(t,riders)) +
  geom_line() +
  ggtitle("Riders on 18Sep")
```


shrinking the amount of data to play with
```{r}
df_s=df2 %>% slice_head(n=1000)
```

rounding down to the nearest 10 minutes, then keeping a data point for each of the 10 minutes
```{r}
df_e=df_s |>
  mutate(t_f=floor_date(t,"10 mins")) %>%
  relocate(t_f,.after=t) %>%
  slice_head(n=1,by=t_f)
```

doing it on the entire data set (df reduced)
```{r}
df_r=df2 |>
  mutate(t_f=floor_date(t,"10 mins")) %>%
  relocate(t_f,.after=t) %>%
  slice_head(n=1,by=t_f)
```


red curve is drawn every 10 minutes
```{r}
p1+
  geom_line(data=df_r %>% filter(day(t)==18),
  color="red")
```
## Getting weather data

uses a function from open meteo to pull data from DC in the desired time period
```{r}
df_w=weather_history("Washington",
                    start = "2023-09-01",
                    end = "2023-09-30",
                    hourly = c("apparent_temperature",
                               "wind_speed_10m",
                               "precipitation")
)
```
## merging bike and weather

play with a small amount of data to test if this works
```{r}
df_s=df2 %>% slice_sample(n=1000)
```

matching it with the closest match to t from df start
```{r}
df_j=df_s %>% left_join(df_w,
                        by=join_by(closest(t>=datetime)))
```

taking datetime to the right of t columns
```{r}
df_j=df_s %>% 
  left_join(df_w,by=join_by(closest(t>=datetime)))  %>%
  relocate(datetime, .after=t)
 
head(df_j)
```

tells us why the previous code is not working (different time zones) 
Look at R for Data Science TimeZones
```{r}
df_j$t[1:5]
df_j$datetime[1:5]
```

using package lubridate to equate the timezone

```{r}
df2$t[1:5]
force_tz(df2$t[1:5],"America/New_York")
```

df 2 corrected times
```{r}
df2c=df2 %>% mutate(t=force_tz(t,tzone="America/New_York")) #corrected
 
df_s2=df2c %>% slice_sample(n=1000)
 
df_j2=df_s2 %>% 
  left_join(df_w,by=join_by(closest(t>=datetime)))  %>%
  relocate(datetime, .after=t)
 
head(df_j2)
```

doing the above to the entire data set and renaming
```{r}
dfc = df2c %>%
  left_join (df_w, by=join_by(closest(t>=datetime))) %>%
  relocate(datetime, .after=t) %>%
  rename(atemp= hourly_apparent_temperature,
         wind = hourly_wind_speed_10m,
         prec=hourly_precipitation)
```


colors the plot every time it rains, precipitation is greater than 1 gets colored
```{r}
p2=dfc %>%
  filter(day(t) == 23)%>% #SHOWS DATA FOR SEPT *date*
  ggplot(aes(t,riders,color=wind)) +
  geom_point()

p2
```
We want to find the difference between times in start and end (ride_time)
```{r}
ride_time = dfc %>%
  mutate(start))
```


make a scatter plot of the ride_time 
Think about what our cut offs should be in the data



